{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Detecção de Fraudes em Cartões de Crédito\n",
    "\n",
    "Neste projeto, iremos abordar o problema das fraudes em cartões de crédito, uma das principais preocupações das instituições financeiras como bancos e *fintechs*. Apenas no Brasil, cerca de 12,1 milhões de pessoas já foram vítimas de algum tipo de fraude financeira no último ano. Traduzindo em valores, os golpes financeiros ultrapassaram a cifra de R$ 1,8 bilhão de prejuízo por ano para os últimos 12 meses.\n",
    "\n",
    "\n",
    "<center><img width=\"5%\" src=\"https://miro.medium.com/max/1400/1*2FEwHebiKtnt4apFZz0wjw.png\" =100x200></center>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dentre essas fraudes, aquelas envolvendo cartões de crédito são de grande relevância uma vez que a sua não-detecção acaretará em prejuízos consideráveis, tanto para o consumidor quanto para a instituição financeira.\n",
    "\n",
    "Um outro fator a ser considerado é a quantidade de falsos positivos, ou seja, aquelas vezes em que você tentou fazer uma compra e teve seu cartão bloqueado preventivamente - o que provavelmente gerou estresse e constrangimento.\n",
    "\n",
    "Por todos esses motivos, o investimento na área de detecção de fraudes por meio de Inteligência Artificial vem crescendo a cada ano, representando uma grande oportunidade em *Data Science*.\n",
    "\n",
    "Dispondo de grandes volumes de dados como base histórica, um algoritmo de machine learning apenas um pouco melhor que os anteriores já representa uma economia de milhões de Reais. E esse é o desafio, aprimorar cada vez mais o uso de algoritmos visando inibir ou evitar transações fraudulentas."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importando os Dados\n",
    "\n",
    "Os dados que usaremos neste projeto foram disponibilizados por algumas empresas européias de cartão de crédito. O *dataset* representa as operações financeiras que aconteceram no período de dois dias, onde foram classificadas 492 fraudes em meio a quase 290 mil transações.\n",
    "\n",
    "Como você pode notar, este é um conjunto de dados extremamente desbalanceado, onde as fraudes representam apenas 0,17% do total.\n",
    "\n",
    "Outro detalhe interessante é que as *features* são todas numéricas, e foram descaracterizadas (por problemas ligados à privacidade e segurança). Assim, os nomes das colunas são representados por $[V1, V2, V3 \\dots, V28]$\n",
    "\n",
    "<p align=center>\n",
    "<img src=\"https://miro.medium.com/max/875/1*6sivl0aoOJ9yM5YMI34U2Q.png\" width=\"50%\"></p>\n",
    "\n",
    "[Na página original dos dados](https://www.kaggle.com/mlg-ulb/creditcardfraud), também é informado que as variáveis passaram por uma transformação conhecida como Análise de Componentes Principais (*Principal Component Analysis* - PCA).\n",
    "\n",
    "A PCA permite a redução da dimensionalidade enquanto mantém o maior número possível de informações. Para conseguir isso, o algoritmo encontra um conjunto novo de recursos - os chamados **componentes**.\n",
    "\n",
    "Esses componentes são em número menor or igual às variáveis originais. No caso deste projeto, os componentes achados pela transformação da PCA são as próprias colunas $[V1, V2, V3 \\dots, V28]$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# importando as bibliotecas\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scikitplot as skplt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# configurar o estilo dos gráficos com o Seaborn\n",
    "\n",
    "sns.set_style('whitegrid')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-11T20:02:29.582973200Z",
     "start_time": "2023-06-11T20:02:29.057475400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] O sistema não pode encontrar o caminho especificado: 'C:\\\\Users\\\\basfe\\\\Documents\\\\Python Scripts\\\\Learning Data Science  - Will\\\\Data'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# carregando arquivo\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchdir\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mC:\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mUsers\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mbasfe\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mDocuments\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mPython Scripts\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mLearning Data Science  - Will\u001B[39;49m\u001B[38;5;130;43;01m\\\\\u001B[39;49;00m\u001B[38;5;124;43mData\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m dados \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcreditcard.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      7\u001B[0m dados\u001B[38;5;241m.\u001B[39mhead()\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] O sistema não pode encontrar o caminho especificado: 'C:\\\\Users\\\\basfe\\\\Documents\\\\Python Scripts\\\\Learning Data Science  - Will\\\\Data'"
     ]
    }
   ],
   "source": [
    "# carregando arquivo\n",
    "\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\basfe\\\\Documents\\\\Python Scripts\\\\Learning Data Science  - Will\\\\Data')\n",
    "dados = pd.read_csv('creditcard.csv')\n",
    "\n",
    "dados.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-06-11T20:02:30.661289400Z",
     "start_time": "2023-06-11T20:02:29.586961900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Análise Exploratória\n",
    "\n",
    "Apenas olhando as cinco primeiras entradas é possível tirar algumas conclusões:\n",
    "\n",
    "* As 5 primeiras entradas permitem entender como a transformação PCA deixou as *features* descaracterizadas (anônimas) e em valores numéricos. Para saber mais sobre PCA, [clique neste *link*](http://www2.ic.uff.br/~aconci/PCA-ACP.pdf).\n",
    "\n",
    "* As colunas `Time` e `Amount` foram preservadas, mantendo seu valor original.\n",
    "\n",
    "* A variável alvo está representada na coluna `Class`, onde:\n",
    "* **0:** Transação normal; e\n",
    "* **1:** Transação fraudulenta;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Verificando abaixo o resumo estatístico, por meio do método `describe()`, podemos confirmar que as variáveis relativas aos componentes principais (transformação PCA) não têm nenhuma discrepância aparente, bem como a coluna `Time`.\n",
    "\n",
    "Em relação à variável `Amount`, nota-se que o valor médio de transações (considerando ambas as classes) é 88.34, mediana igual a 22.00 e desvio padrão de 250.12. Atingindo o valor máximo de 25691.16, a maioria das transações financeiras é composta em sua maioria por quantias menores - como esperado.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# resumo estatístico\n",
    "\n",
    "dados.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quanto à qualidade do *dataset*, este não apresentou nenhum valor ausente ou que demandasse uma etapa de limpeza. Na função abaixo, perceba que o maior valor por coluna para valores nulos é zero, o que confirma que não há valores ausentes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# verificando dados missing values (dados ausentes)\n",
    "\n",
    "dados.isnull().sum().max()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como é [informado na descrição dos dados](https://www.kaggle.com/mlg-ulb/creditcardfraud), as entradas relativas à transações fraudulentas correspondem a 0,17% do total.\n",
    "\n",
    "O gráfico de barras mostra como essa discrepância se torna nítida e visível. Na prática, isso interfere no desempenho do modelo, e será necessário fazer um balanceamento dos dados antes de alimentar o modelo final de classificação."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ver o balanceamento das classes\n",
    "print(dados.Class.value_counts())\n",
    "print(\"\\nFraudes representam {:.4f}% do dataset.\\n\".format((dados[dados.Class == 1].shape[0] / dados.shape[0]) * 100))\n",
    "\n",
    "# plotar gráfico de barras para as Classes\n",
    "fig, ax = plt.subplots(figsize = (20,6))\n",
    "sns.countplot('Class', data=dados, ax=ax)\n",
    "ax.set_title('Distribuição das Classes')\n",
    "plt.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotou-se também dois gráficos a fim de comparar as distribuições das 2 classes ao longo da dimensão tempo (`Time`). No entanto, não foi identificada nenhum informação a partir das distribuições de frequência abaixo."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(12,6))\n",
    "\n",
    "num_bins = 40\n",
    "\n",
    "ax[0].hist(dados.Time[dados.Class == 0], bins=num_bins)\n",
    "ax[0].set_title('Normal')\n",
    "\n",
    "ax[1].hist(dados.Time[dados.Class == 1], bins=num_bins)\n",
    "ax[1].set_title('Fraud')\n",
    "\n",
    "plt.xlabel('Tempo (segundos)')\n",
    "plt.ylabel('Transações')\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seguindo a análise exploratória, plotou-se os *boxplots* para ver se há alguma diferença no padrão transações em relação à dimensão `Amount`.\n",
    "\n",
    "De uma maneira geral, percebe-se uma distribuição diferente para as duas classes, o que provavelmente irá contribuir para o treinamento do modelo de *machine learning*."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "\n",
    "sns.boxplot(dados.Class, dados.Amount)\n",
    "plt.ylim((-20, 400))\n",
    "plt.xticks([0, 1], ['Normal', 'Fraude'])\n",
    "\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As informações estatísticas para `df.Class == 1` mostram que a sua média exata está em 118.13 e a mediana em 9.21."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dados.query('Class == 1 & Amount < 2000')['Amount'].describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "O gráfico de densidade é muito útil para compararmos as distribuições de cada variável para cada classe e ver quais as mais importantes para detecção de anomalias.\n",
    "\n",
    "O que se procura nesse tipo de visualização são distribuições que diferem uma da outra, permitindo identificar fraudes mais facilmente. Veja como exemplo as variáveis `V3`, `V4`, `V10` e `V11`, como elas são bem distintas.\n",
    "\n",
    "Por outro lado, variáveis como `V8`, `V13` e `V15` são muito similares, apresentando aproximadamente o mesmo comportamento."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "column_names = dados.drop(['Class', 'Amount', 'Time'], axis=1).columns\n",
    "num_plots = len(column_names)\n",
    "df_class_0 = dados.query('Class == 0')\n",
    "df_class_1 = dados.query('Class == 1')\n",
    "\n",
    "fig, ax = plt.subplots(nrows=7, ncols=4, figsize=(18,18))\n",
    "fig.subplots_adjust(hspace=1, wspace=1)\n",
    "\n",
    "idx = 0\n",
    "for col in column_names:\n",
    "    idx += 1\n",
    "    plt.subplot(7, 4, idx)\n",
    "    sns.kdeplot(df_class_0[col], label=\"Class 0\", shade=True)\n",
    "    sns.kdeplot(df_class_1[col], label=\"Class 1\", shade=True)\n",
    "    plt.title(col, fontsize=10)\n",
    "\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Resumidamente, algumas observações principais que puderam ser extraídas dessa etapa exploratória foram:\n",
    "\n",
    "* O *dataset* está muito desbalanceado, uma vez que as transações fraudulentas representam apenas 0,17% das entradas totais.\n",
    "* Não existem valores ausentes ou nulos no *dataframe*.\n",
    "* Uma vez que a PCA é sensível à escala das variáveis, assume-se a premissa que as *features* originais foram padronizadas.\n",
    "* As colunas `Time` e `Amount` não estão normalizadas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
